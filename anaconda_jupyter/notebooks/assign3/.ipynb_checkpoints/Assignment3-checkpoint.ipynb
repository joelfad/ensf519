{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> ENSF 519.01 Applied Data Scince </center></h1>\n",
    "<h2> <center> Assignment 3: Supervised learning and dimension reduction (25 marks)</center></h2>\n",
    "<h2> <center> Due: March 9, 2018. To be submitted on D2L Dropbox </center></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment the focus is on ensemble models for learning and how preprocessing can help improving prediction scores. There are 5 parts that each may use different dataset. All datasets are available as csv files on D2L. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part A. Defect Prediction - Voting Ensemble Model (4 marks)</h2>\n",
    "<br><br>\n",
    "In this section you need to repeat what you did in your last assignment, HW2 at Part C, but this time you should use VotingClassifier function of SKlearn rather than the Combine function explained in that assignment.\n",
    "<br>\n",
    "Basically, you predict defects on the same NASA dataset using a simple ensemble model consisting of Logistic Regression, Gaussian Naive Bayes, and K-Nearest Neighbor estimators. You need to try both \"soft voting\" and \"hard voting\" options. \n",
    "<br>\n",
    "All models and functions should be called by their default parameters.\n",
    "<br>\n",
    "Same as HW2, you calculate each combined score 30 times (with different random_state seeds for the train_test_splits).\n",
    "Finally, visualize the results as three boxplots of 30 runs per: a) soft voting, b) hard voting, and c) your combined modelâ€™s results from HW2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part B. Linear Regression, Random Forest, and Gradient Boosting (5 marks) </h2>\n",
    "\n",
    "In this section, our task is again defect prediction. However, this time each artifact may have zero, one, or more defects. Thus our job is not just predicting defective vs. non-defective targets, but we would like to predict the exact number of defects. This is useful since one can prioritize QA effort based on the number of defects as a sign of severity. To do so we treat the problem as a regression problem not a classification problem.\n",
    "\n",
    "- <b> If we would use a classification rather than regression, explain what kind of classification problem this question could fit in and why? Explain why a regression solution is a better choice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Your Answer:</b> ..................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build your models you should follow these steps: \n",
    "<br>\n",
    "- read the data from \"OO-DefectPrediction.csv\" \n",
    "\n",
    "- apply a basic linear regression. (with all default parameters)\n",
    "\n",
    "- apply random forest regression. (with all default parameters, that is e.g., n_estimators=10, etc.)\n",
    "\n",
    "- apply gradient boosting regression. (with all default parameters, that is e.g., n_estimators=100, etc.)\n",
    "\n",
    "- calculate all R^2s. Note: You should implement R^2s as follows: \n",
    "  - round each predicted value (y_pred) to create your rounded_y_pred (e.g., 1.6 --> 1 and 0.4 --> 0)\n",
    "  - call sklearn.metrics.r2_score with (y_true, rounded_y_pred)\n",
    "\n",
    "\n",
    "- Run each model 30 times, with a new train test split. Set random_state to range(1,30) every time you create a train-test set. Also use the same seed value ([1..30]) for the corresponding RandomForestRegressor and GradientBoostingRegressor's  random_state parameter. Keep the test set size as default. \n",
    "\n",
    "- Finally, print the median score of those 30 runs for the three models, on the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part C. Improving regression by tuning (5 marks)</h2>\n",
    "<br><br>\n",
    "In this part, we want to improve the R^2's achieved by the default setups, in Part B. To reduce the scope of the assignment we only focus on RandomForestRegressor, in this part. We approach the problem by tuning the RandomForestRegressor's main parameters (max_depth, and n_estimators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You first need to apply RandomForestRegressor with different values of max_depth as [3,4,5,6,7,None] (None means no maximum). n_estimators should be tested with this values [10,20,30,...,100]. \n",
    "\n",
    "Keep other parameters of RandomForestRegressor the same as Part B. \n",
    "\n",
    "Run each configuration 30 times (with random seeds [1..30]) and calculate the median R^2 per configuration. \n",
    "\n",
    "Find the best configuration of n_estimators and max_depth among the ones you tested, with the highest median R^2. \n",
    "\n",
    "Report the best configuration you found by printing the max_depth, the n_estimators, and the resulting median R^2.\n",
    "\n",
    "How much improvement you achieved compared to the default set up of RandomForestRegressor in Part B?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part D. Dimension reduction - feature selection (7 marks)</h1>\n",
    "<br><br>\n",
    "\n",
    "In this section, we want to compare the dimension reduction ability of PCA with linear regression models. \n",
    "\n",
    "To use linear regression model as a dimension reduction technique, we fit the model and pick the most informative features and represent the data with only those features. \n",
    "\n",
    "Our dataset is \"ApacheAll.csv\", which records some performance measurements of an APACHE Web Server, which have been collected using a standard benchmark. See https://zenodo.org/record/322483#.WoZap5PwaRv for more details about the dataset.\n",
    "\n",
    "<br>\n",
    "Steps:  \n",
    "- Apply Linear Regression on \"ApacheAll.csv\" data and find the coefficient of each feature and pick the two greatest ones. Reduce the dimensionality of your dataset by only keeping these two features in your train and test set.\n",
    "    - use default parameters.\n",
    "- Fit a PCA model on the original training set and pick the first two principal components (which contains most of the variations). Transform both training and test sets to this new space (2 dimensions).\n",
    "    - use default parameters.  \n",
    "    \n",
    "- Build 3 random forest regression models: a) use the train and test set given by linear regression selected features, b) use PCA transformed data, c) use the original training and test sets.\n",
    "    \n",
    "    \n",
    "- repeat the above three steps 30 times with random_state range [1..30] for both train/test splitter and RandomForestRegressor. Note that for each run a new PCA and Linear regression should be applied (i.e., do not transform new data based on the old fitted models)\n",
    "\n",
    "- For all three models \n",
    "    - print the median regression scores (over 30 runs) \n",
    "\n",
    "- Explain your observation with respect to relative performance of PCA and linear regression for dimension reduction and why this has happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part E. Dimension reduction for visualization (4 marks)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main use cases of dimensionality reduction techniques is for visualization of high dimensional datasets.\n",
    "In this part, we use the same OO-DefectPrediction.csv dataset and visualize it in just two dimensions.\n",
    "\n",
    "Steps :\n",
    "\n",
    "- Read the data from \"OO-DefectPrediction.csv\".\n",
    "- Transform the data to principal components using pca. \n",
    "- visualize data using the two first principal components. You should use different color code to visualize number of bugs. \n",
    "- explain your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
